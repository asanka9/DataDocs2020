<div class="container">
  <!--What are the disadvantages of TF-IDF and BagOfWords?-->
  <div>
    <h5>What are the disadvantages of TF-IDF and BagOfWords?</h5>
    <P>Both BOW and TF-IDF approach <i>semantic information</i> is not
      stored, TF-IDF only gives importance to uncommon words, and there
      is a chance of overfitting.we can use Word2Vec to overcome this problem
    </P>
  </div>

  <!--Word2Vec-->
  <div>
    <h5>Word2Vec</h5>
    <img src="https://miro.medium.com/max/3902/1*hELlVp9hmZbDZVFstS61pg.png" class="img-fluid" width="500px" height="300px">
    <p>in this specific model, each word is basically represented as a
      vector of 32 or more dimensions instead of a single number. Here the
      semantic information and relationships between different words are also preserved </p>
    <img src="https://developers.google.com/machine-learning/crash-course/images/linear-relationships.svg"  class="img-fluid" width="500px" height="300px"><br>
    <b>Steps to Create Word2Vec</b>
    <ul>
      <li>Tokenization of the sentences</li>
      <li>Create Histograms</li>
      <li>Take most frequent words</li>
      <li>Create a matrix with all the unique words, it also represents the occurrence relation between the words</li>
    </ul>
  </div>
</div>
